{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm, trange\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtext\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text1</th>\n",
       "      <th>target</th>\n",
       "      <th>text2</th>\n",
       "      <th>case_number</th>\n",
       "      <th>text3</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105000</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nТимашкова ...</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>А54-4312/2008</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>[общество, ограничить, ответственность, ORG, д...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105001</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nНикулова М...</td>\n",
       "      <td>3</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nНикулова М...</td>\n",
       "      <td>А62-6708/2008</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nНикулова М...</td>\n",
       "      <td>[арбитражный, апелляционный, суд, никулов, м, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105002</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nСтаханова ...</td>\n",
       "      <td>36</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>А23-1432/2008</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>[открытый, акционерный, общество, ORG, далее, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105003</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nКапустина ...</td>\n",
       "      <td>6</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nКапустина ...</td>\n",
       "      <td>А23-2543/2009</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nКапустина ...</td>\n",
       "      <td>[арбитражный, апелляционный, суд, капустин, ла...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105004</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nТучкова Ол...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>А62-2328/2009</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>[закрытый, акционерный, общество, ORG, далее, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idx                                              text1  target  \\\n",
       "0  105000  \\n20 арбитражный апелляционный суд\\nТимашкова ...      19   \n",
       "1  105001  \\n20 арбитражный апелляционный суд\\nНикулова М...       3   \n",
       "2  105002  \\n20 арбитражный апелляционный суд\\nСтаханова ...      36   \n",
       "3  105003  \\n20 арбитражный апелляционный суд\\nКапустина ...       6   \n",
       "4  105004  \\n20 арбитражный апелляционный суд\\nТучкова Ол...       3   \n",
       "\n",
       "                                               text2    case_number  \\\n",
       "0  </span></b></p>\\r\\n<p style=\"text-align:center...  А54-4312/2008   \n",
       "1  \\n20 арбитражный апелляционный суд\\nНикулова М...  А62-6708/2008   \n",
       "2  </span></b></p>\\r\\n<p style=\"text-align:center...  А23-1432/2008   \n",
       "3  \\n20 арбитражный апелляционный суд\\nКапустина ...  А23-2543/2009   \n",
       "4  </span></b></p>\\r\\n<p style=\"text-align:center...  А62-2328/2009   \n",
       "\n",
       "                                               text3  \\\n",
       "0  </span></b></p>\\r\\n<p style=\"text-align:center...   \n",
       "1  \\n20 арбитражный апелляционный суд\\nНикулова М...   \n",
       "2  </span></b></p>\\r\\n<p style=\"text-align:center...   \n",
       "3  \\n20 арбитражный апелляционный суд\\nКапустина ...   \n",
       "4  </span></b></p>\\r\\n<p style=\"text-align:center...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [общество, ограничить, ответственность, ORG, д...  \n",
       "1  [арбитражный, апелляционный, суд, никулов, м, ...  \n",
       "2  [открытый, акционерный, общество, ORG, далее, ...  \n",
       "3  [арбитражный, апелляционный, суд, капустин, ла...  \n",
       "4  [закрытый, акционерный, общество, ORG, далее, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('raw_data/court_texts.csv', names=['idx', 'text1', 'target', 'text2', 'case_number', 'text3', 'tokenized'])\n",
    "train_data.tokenized = train_data.tokenized.apply(eval)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7096258919774281"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data.tokenized.map(len) < 160).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text1</th>\n",
       "      <th>target</th>\n",
       "      <th>text2</th>\n",
       "      <th>case_number</th>\n",
       "      <th>text3</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>target_descr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105000</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nТимашкова ...</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>А54-4312/2008</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>[общество, ограничить, ответственность, ORG, д...</td>\n",
       "      <td>Споры по делам об оспаривании решений налоговы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105001</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nНикулова М...</td>\n",
       "      <td>3</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nНикулова М...</td>\n",
       "      <td>А62-6708/2008</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nНикулова М...</td>\n",
       "      <td>[арбитражный, апелляционный, суд, никулов, м, ...</td>\n",
       "      <td>Споры о неисполнении или ненадлежащем исполнен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105002</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nСтаханова ...</td>\n",
       "      <td>36</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>А23-1432/2008</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>[открытый, акционерный, общество, ORG, далее, ...</td>\n",
       "      <td>Споры по делам об оспаривании нормативных прав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105003</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nКапустина ...</td>\n",
       "      <td>6</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nКапустина ...</td>\n",
       "      <td>А23-2543/2009</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nКапустина ...</td>\n",
       "      <td>[арбитражный, апелляционный, суд, капустин, ла...</td>\n",
       "      <td>Споры о неисполнении или ненадлежащем исполнен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105004</td>\n",
       "      <td>\\n20 арбитражный апелляционный суд\\nТучкова Ол...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>А62-2328/2009</td>\n",
       "      <td>&lt;/span&gt;&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p style=\"text-align:center...</td>\n",
       "      <td>[закрытый, акционерный, общество, ORG, далее, ...</td>\n",
       "      <td>Споры о неисполнении или ненадлежащем исполнен...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idx                                              text1  target  \\\n",
       "0  105000  \\n20 арбитражный апелляционный суд\\nТимашкова ...      19   \n",
       "1  105001  \\n20 арбитражный апелляционный суд\\nНикулова М...       3   \n",
       "2  105002  \\n20 арбитражный апелляционный суд\\nСтаханова ...      36   \n",
       "3  105003  \\n20 арбитражный апелляционный суд\\nКапустина ...       6   \n",
       "4  105004  \\n20 арбитражный апелляционный суд\\nТучкова Ол...       3   \n",
       "\n",
       "                                               text2    case_number  \\\n",
       "0  </span></b></p>\\r\\n<p style=\"text-align:center...  А54-4312/2008   \n",
       "1  \\n20 арбитражный апелляционный суд\\nНикулова М...  А62-6708/2008   \n",
       "2  </span></b></p>\\r\\n<p style=\"text-align:center...  А23-1432/2008   \n",
       "3  \\n20 арбитражный апелляционный суд\\nКапустина ...  А23-2543/2009   \n",
       "4  </span></b></p>\\r\\n<p style=\"text-align:center...  А62-2328/2009   \n",
       "\n",
       "                                               text3  \\\n",
       "0  </span></b></p>\\r\\n<p style=\"text-align:center...   \n",
       "1  \\n20 арбитражный апелляционный суд\\nНикулова М...   \n",
       "2  </span></b></p>\\r\\n<p style=\"text-align:center...   \n",
       "3  \\n20 арбитражный апелляционный суд\\nКапустина ...   \n",
       "4  </span></b></p>\\r\\n<p style=\"text-align:center...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [общество, ограничить, ответственность, ORG, д...   \n",
       "1  [арбитражный, апелляционный, суд, никулов, м, ...   \n",
       "2  [открытый, акционерный, общество, ORG, далее, ...   \n",
       "3  [арбитражный, апелляционный, суд, капустин, ла...   \n",
       "4  [закрытый, акционерный, общество, ORG, далее, ...   \n",
       "\n",
       "                                        target_descr  \n",
       "0  Споры по делам об оспаривании решений налоговы...  \n",
       "1  Споры о неисполнении или ненадлежащем исполнен...  \n",
       "2  Споры по делам об оспаривании нормативных прав...  \n",
       "3  Споры о неисполнении или ненадлежащем исполнен...  \n",
       "4  Споры о неисполнении или ненадлежащем исполнен...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = {\n",
    "    \"16\": \"Корпоративные споры\",\n",
    "    \"36\": \"Споры по делам об оспаривании нормативных правовых актов в области таможенного дела\",\n",
    "    \"3\": \"Споры о неисполнении или ненадлежащем исполнении обязательств по договорам купли-продажи\",\n",
    "    \"35\": \"Споры по делам об оспаривании зарегистрированных прав на недвижимое имущество и сделок с ним\",\n",
    "    \"21\": \"Споры о привлечении к административной ответственности\",\n",
    "    \"1\": \"Споры о заключении договоров(контрактов)\",\n",
    "    \"28\": \"Споры по делам об оспаривании ненормативных правовых актов Правительства РФ\",\n",
    "    \"25\": \"Споры по введению процедур банкротства\",\n",
    "    \"19\": \"Споры по делам об оспаривании решений налоговых органов о привлечении к административной ответственности\",\n",
    "    \"32\": \"Споры о возмещении вреда в связи с обеспечением иска\",\n",
    "    \"22\": \"Споры о признании права собственности\",\n",
    "    \"26\": \"Споры об оспаривании решений третейских судов\",\n",
    "    \"5\": \"Споры о неисполнении или ненадлежащем исполнении обязательств по договорам аренды\",\n",
    "    \"2\": \"Споры по искам антимонопольных органов об оспаривании нормативных правовых актов\",\n",
    "    \"6\": \"Споры о неисполнении или ненадлежащем исполнении обязательств по договорам подряда\",\n",
    "    \"4\": \"Споры о признании договоров недействительными\",\n",
    "    \"27\": \"Споры по делам об оспаривании ненормативных правовых актов Президента РФ\",\n",
    "    \"20\": \"Споры о ненадлежащем исполнении и возмещении убытков\",\n",
    "    \"17\": \"Споры, связанные с созданием, реорганизацией и ликвидацией юридических лиц\",\n",
    "    \"24\": \"Споры об обжаловании решений Роспатента\",\n",
    "    \"10\": \"Споры о неисполнении или ненадлежащем исполнении обязательств по договорам займа и кредита\",\n",
    "    \"9\": \"Споры о неисполнении или ненадлежащем исполнении обязательств по договорам в сфере транспортной деятельности\",\n",
    "    \"37\": \"Споры об изъятии, прекращении или ограничении права на земельный участок\",\n",
    "    \"14\": \"Споры о неисполнении или ненадлежащем исполнении обязательств по посредническим договорам\",\n",
    "    \"12\": \"Споры о неисполнении или ненадлежащем исполнении обязательств по договорам хранения\",\n",
    "    \"11\": \"Споры о неисполнении или ненадлежащем исполнении обязательств по договорам банковского счета, при осуществлении расчетов\",\n",
    "    \"13\": \"Споры о неисполнении или ненадлежащем исполнении обязательств по договорам возмездного оказания услуг\",\n",
    "    \"15\": \"Споры о неисполнении или ненадлежащем исполнении обязательств по иным видам договоров\",\n",
    "    \"33\": \"Споры о создании, реорганизации и ликвидации организаций\",\n",
    "    \"18\": \"Споры по делам об оспаривании ненормативных правовых актов, решений и действий (бездействия) государственных внебюджетных органов\",\n",
    "    \"23\": \"Споры, связанные с охраной интеллектуальной собственности\",\n",
    "    \"34\": \"Споры об уклонении от государственной регистрации юридических лиц и индивидуальных предпринимателей\",\n",
    "    \"30\": \"Нет\",\n",
    "    \"7\": \"Споры по искам антимонопольных органов об изменении или расторжении договора\",\n",
    "    \"0\": \"Споры, возникающие в связи с неисполнением или ненадлежащим исполнением обязательств из совершения с землей сделок купли-продажи\",\n",
    "    \"8\": \"Споры о неисполнении или ненадлежащем исполнении обязательств по договорам долевого участия в строительстве\",\n",
    "    \"29\": \"Экономические споры между субъектами Российской Федерации\"\n",
    "}\n",
    "train_data['target_descr'] = [cats[str(t)] for t in train_data.target]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     21706\n",
       "25    19687\n",
       "21    12906\n",
       "36    11643\n",
       "14     7850\n",
       "6      6427\n",
       "12     6374\n",
       "19     5849\n",
       "5      5837\n",
       "2      4584\n",
       "26     4143\n",
       "28     4136\n",
       "32     3728\n",
       "22     3370\n",
       "37     2413\n",
       "4      2007\n",
       "16     1924\n",
       "9      1859\n",
       "17     1842\n",
       "10     1498\n",
       "35      812\n",
       "1       715\n",
       "33      444\n",
       "24      396\n",
       "34      259\n",
       "0       252\n",
       "13      198\n",
       "15      193\n",
       "18      176\n",
       "20      156\n",
       "27      140\n",
       "8       139\n",
       "23      130\n",
       "11       88\n",
       "7        55\n",
       "30       36\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Споры о неисполнении или ненадлежащем исполнении обязательств по договорам купли-продажи                                             21706\n",
       "Споры по введению процедур банкротства                                                                                               19687\n",
       "Споры о привлечении к административной ответственности                                                                               12906\n",
       "Споры по делам об оспаривании нормативных правовых актов в области таможенного дела                                                  11643\n",
       "Споры о неисполнении или ненадлежащем исполнении обязательств по посредническим договорам                                             7850\n",
       "Споры о неисполнении или ненадлежащем исполнении обязательств по договорам подряда                                                    6427\n",
       "Споры о неисполнении или ненадлежащем исполнении обязательств по договорам хранения                                                   6374\n",
       "Споры по делам об оспаривании решений налоговых органов о привлечении к административной ответственности                              5849\n",
       "Споры о неисполнении или ненадлежащем исполнении обязательств по договорам аренды                                                     5837\n",
       "Споры по искам антимонопольных органов об оспаривании нормативных правовых актов                                                      4584\n",
       "Споры об оспаривании решений третейских судов                                                                                         4143\n",
       "Споры по делам об оспаривании ненормативных правовых актов Правительства РФ                                                           4136\n",
       "Споры о возмещении вреда в связи с обеспечением иска                                                                                  3728\n",
       "Споры о признании права собственности                                                                                                 3370\n",
       "Споры об изъятии, прекращении или ограничении права на земельный участок                                                              2413\n",
       "Споры о признании договоров недействительными                                                                                         2007\n",
       "Корпоративные споры                                                                                                                   1924\n",
       "Споры о неисполнении или ненадлежащем исполнении обязательств по договорам в сфере транспортной деятельности                          1859\n",
       "Споры, связанные с созданием, реорганизацией и ликвидацией юридических лиц                                                            1842\n",
       "Споры о неисполнении или ненадлежащем исполнении обязательств по договорам займа и кредита                                            1498\n",
       "Споры по делам об оспаривании зарегистрированных прав на недвижимое имущество и сделок с ним                                           812\n",
       "Споры о заключении договоров(контрактов)                                                                                               715\n",
       "Споры о создании, реорганизации и ликвидации организаций                                                                               444\n",
       "Споры об обжаловании решений Роспатента                                                                                                396\n",
       "Споры об уклонении от государственной регистрации юридических лиц и индивидуальных предпринимателей                                    259\n",
       "Споры, возникающие в связи с неисполнением или ненадлежащим исполнением обязательств из совершения с землей сделок купли-продажи       252\n",
       "Споры о неисполнении или ненадлежащем исполнении обязательств по договорам возмездного оказания услуг                                  198\n",
       "Споры о неисполнении или ненадлежащем исполнении обязательств по иным видам договоров                                                  193\n",
       "Споры по делам об оспаривании ненормативных правовых актов, решений и действий (бездействия) государственных внебюджетных органов      176\n",
       "Споры о ненадлежащем исполнении и возмещении убытков                                                                                   156\n",
       "Споры по делам об оспаривании ненормативных правовых актов Президента РФ                                                               140\n",
       "Споры о неисполнении или ненадлежащем исполнении обязательств по договорам долевого участия в строительстве                            139\n",
       "Споры, связанные с охраной интеллектуальной собственности                                                                              130\n",
       "Споры о неисполнении или ненадлежащем исполнении обязательств по договорам банковского счета, при осуществлении расчетов                88\n",
       "Споры по искам антимонопольных органов об изменении или расторжении договора                                                            55\n",
       "Нет                                                                                                                                     36\n",
       "Name: target_descr, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_sizes = train_data.target_descr.value_counts()\n",
    "cat_sizes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    NamesExtractor,\n",
    "    AddrExtractor,\n",
    "    MoneyExtractor,\n",
    "    DatesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "\n",
    "names_extractor = NamesExtractor(morph_vocab)\n",
    "addr_extractor = AddrExtractor(morph_vocab)\n",
    "money_extractor = MoneyExtractor(morph_vocab)\n",
    "dates_extractor = DatesExtractor(morph_vocab)\n",
    "\n",
    "def replace_date(x, token='DATE'):\n",
    "    date_extracts = list(dates_extractor(x))\n",
    "    if len(date_extracts) == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return_text = x\n",
    "        for date_extract in date_extracts: \n",
    "            st_idx = date_extract.start\n",
    "            end_idx = date_extract.stop            \n",
    "            return_text = return_text.replace(x[st_idx:end_idx], token)\n",
    "        return return_text\n",
    "\n",
    "def replace_address(x, token='ADDR'):\n",
    "    addr_extracts = list(addr_extractor(x))\n",
    "    if len(addr_extracts) == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return_text = x\n",
    "        for addr_extract in addr_extracts: \n",
    "            if addr_extract.fact.type in ['улица', 'дом']:\n",
    "                st_idx = addr_extract.start\n",
    "                end_idx = addr_extract.stop            \n",
    "                return_text = return_text.replace(x[st_idx:end_idx], token)\n",
    "        return return_text\n",
    "\n",
    "def replace_money(x, quantiles=None):\n",
    "    # text = judgment_w_motive.motiv_part.iloc[0]\n",
    "    money_extracts = list(money_extractor(x))\n",
    "    if len(money_extracts) == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return_text = x\n",
    "        for money_extract in money_extracts:\n",
    "            print(money_extract)\n",
    "            st_idx = money_extract.start\n",
    "            end_idx = money_extract.stop\n",
    "            currency = money_extract.fact.currency\n",
    "            if currency != 'RUB':\n",
    "                return_text = return_text.replace(x[st_idx:end_idx], 'MONEY_F')\n",
    "                continue\n",
    "            amount = money_extract.fact.amount\n",
    "            if amount < 4631.79:\n",
    "                print('money_0')\n",
    "                return_text = return_text.replace(x[st_idx:end_idx], 'MONEY_0')\n",
    "                continue\n",
    "            if amount <= 168830.91:\n",
    "                return_text = return_text.replace(x[st_idx:end_idx], 'MONEY_1')\n",
    "                continue\n",
    "            return_text = return_text.replace(x[st_idx:end_idx], 'MONEY_2')\n",
    "            \n",
    "        return return_text\n",
    "\n",
    "def money_in_span(x):\n",
    "    for money_token in ['MONEY_F', 'MONEY_0', 'MONEY_1', 'MONEY_2', 'DATE']:\n",
    "        if money_token in x:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def replace_org(x, leave_org = None):\n",
    "    doc = Doc(x)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "    return_text = x\n",
    "    for span in doc.spans:\n",
    "        if span.type == 'ORG':\n",
    "            if ((leave_org is not None) and (span.text in leave_org)) or money_in_span(span.text):\n",
    "                continue\n",
    "            else:\n",
    "                word = 'ORG'\n",
    "                return_text = return_text.replace(span.text, word)\n",
    "    return return_text\n",
    "\n",
    "org_freq = pd.read_csv('org_freq.csv')\n",
    "leave_org = (org_freq[org_freq.freq > 65].org_name.values).tolist()\n",
    "\n",
    "def prepare_russian_text(raw_text):\n",
    "    doc = Doc(raw_text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "\n",
    "    prepared_text = []\n",
    "    for token in doc.tokens:\n",
    "        if token.text in ['ORG', 'DATE', 'MONEY_0', 'MONEY_1', 'MONEY_2']:\n",
    "            prepared_text.append(token.text)\n",
    "            continue\n",
    "        skip_pos = ['PUNCT', 'ADP', 'SCONJ', 'CCONJ', 'SYM', 'NUM']\n",
    "        if token.pos not in skip_pos:\n",
    "            try:\n",
    "                token.lemmatize(morph_vocab)\n",
    "                prepared_text.append(token.lemma.lower())\n",
    "            except Exception as ex:\n",
    "                prepared_text.append(token.text.lower())\n",
    "    return prepared_text\n",
    "\n",
    "def pipeline(text: str):\n",
    "    try:\n",
    "        text = re.sub('<(?:\"[^\"]*\"[\\'\"]*|\\'[^\\']*\\'[\\'\"]*|[^\\'\">])+>', '', text.replace('&nbsp;', ''))\n",
    "        text_dates_removed = replace_date(text, '')\n",
    "        # text_addr_removed = replace_address(text_dates_removed)\n",
    "        # text_money_replaced = replace_money(text_addr_removed)\n",
    "        text_money_replaced = replace_money(text_dates_removed)\n",
    "        text_money_org_replaced = replace_org(text_money_replaced, leave_org)\n",
    "        lemmatised_text = prepare_russian_text(text_money_org_replaced)\n",
    "        return lemmatised_text\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n&nbsp;\\r\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 общество с ограниченной ответственностью «Ярмарка» (далее – ООО «Ярмарка», Общество) обратилось в Арбитражный суд Рязанской области с заявлением о признании незаконным бездействия Администрации г.Рязани, выраженное в нерассмотрении заявления о выдаче разрешения на размещение и эксплуатацию временного сооружения №769-ВС4/08 от 11.07.2008, поданного ООО «Ярмарка» в установленный срок, как несоответствующее требованиям Положения о временных сооружениях на территории г.Рязани, утвержденного решением Рязанского городского Совета от 26.04.2007 №309-III (далее – Положение о временных сооружениях), в качестве устранения нарушения обязать Администрацию г.Рязани перезаключить договор совместного использования объекта недвижимости под временным строением, расположенным по адресу: г.Рязань, ул. Горького, д.1(с учетом уточнения).\\r\\nРешением Арбитражного суда Рязанской области от 17.02.2009 '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('<(?:\"[^\"]*\"[\\'\"]*|\\'[^\\']*\\'[\\'\"]*|[^\\'\">])+>', '', train_data.text3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 250\n",
    "list(zip(pipeline(train_data.text3[i]), train_data.tokenized[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatised concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('court_texts.csv', names=['idx', 'text1', 'target', 'text2', 'case_number', 'text3', 'tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "new_train_data = pd.read_csv('train_trans.csv')\n",
    "new_val_data = pd.read_csv('val_trans.csv')\n",
    "\n",
    "def pipeline(text: str):\n",
    "    try:\n",
    "        text = ' '.join(text.split())\n",
    "        text = text.replace('&quot;', '\"')\n",
    "        return text\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "texts_train, texts_val, targets_train, targets_val = train_test_split(\n",
    "    train_data.tokenized.map(lambda s: ' '.join(eval(s))), train_data.target,\n",
    "    test_size=0.1, stratify=train_data.target, random_state=123\n",
    ")\n",
    "train_mask = list(new_train_data.text.map(pipeline).str.len() > 32)\n",
    "pd.DataFrame({'text': texts_train.reset_index(drop=True)[train_mask], 'target': targets_train.reset_index(drop=True)[train_mask]}).to_csv('train_trans_lem.csv', index=False)\n",
    "val_mask = list(new_val_data.text.map(pipeline).str.len() > 32)\n",
    "pd.DataFrame({'text': texts_val.reset_index(drop=True)[val_mask], 'target': targets_val.reset_index(drop=True)[val_mask]}).to_csv('val_trans_lem.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(list(map(len, train_data['tokenized'])), 0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data['tokenized'], specials=['<pad>', '<unk>'], min_freq=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f182445cb9e54ae6b8ea39773563ee7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a695d5f61d43de8e68e71815d5052a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 512\n",
    "\n",
    "train_tokens = []\n",
    "for text in tqdm(train_data['tokenized']):\n",
    "    tokens = [vocab[word] if word in vocab else vocab['<unk>'] for word in text]\n",
    "    train_tokens += [tokens]\n",
    "\n",
    "tokenized_train = torch.full((len(train_tokens), max_length), vocab['<pad>'], dtype=torch.int32)\n",
    "for i, tokens in tqdm(enumerate(train_tokens)):\n",
    "    length = min(max_length, len(tokens))\n",
    "    tokenized_train[i, :length] = torch.tensor(tokens[:length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_train, tokenized_val, targets_train, targets_val = train_test_split(\n",
    "#     tokenized_train, train_data.target, test_size=0.1, stratify=train_data.target, random_state=123\n",
    "# )\n",
    "tokenized_train, tokenized_val, targets_train, targets_val = train_test_split(\n",
    "    train_data.tokenized, train_data.target, test_size=0.1, stratify=train_data.target, random_state=123\n",
    ")\n",
    "tokenized_train.map(lambda l: ' '.join(l)).to_csv('interpreting-cnn-for-text/legal_dataset/train.txt.tok', header=False, index=False)\n",
    "tokenized_val.map(lambda l: ' '.join(l)).to_csv('interpreting-cnn-for-text/legal_dataset/test.txt.tok', header=False, index=False)\n",
    "targets_train.to_csv('interpreting-cnn-for-text/legal_dataset/train.cat', header=False, index=False)\n",
    "targets_val.to_csv('interpreting-cnn-for-text/legal_dataset/test.cat', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(tokenized_train, torch.tensor(targets_train.to_list()))\n",
    "val_dataset = torch.utils.data.TensorDataset(tokenized_val, torch.tensor(targets_val.to_list()))\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout_proba):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)        \n",
    "        self.conv_0 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[0], embedding_dim))\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[1], embedding_dim))\n",
    "        self.conv_2 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[2], embedding_dim))\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_proba)\n",
    "        \n",
    "    def forward(self, x):                \n",
    "        #x = [batch size, sent len]\n",
    "        embedded = self.embedding(x)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
    "        conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
    "        conved_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim=1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_trans_trim.csv')\n",
    "texts_train, targets_train = train_data.text, train_data.target\n",
    "val_data = pd.read_csv('val_trans_trim.csv')\n",
    "texts_val, targets_val = val_data.text, val_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    NamesExtractor,\n",
    "    AddrExtractor,\n",
    "    MoneyExtractor,\n",
    "    DatesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "\n",
    "names_extractor = NamesExtractor(morph_vocab)\n",
    "addr_extractor = AddrExtractor(morph_vocab)\n",
    "money_extractor = MoneyExtractor(morph_vocab)\n",
    "dates_extractor = DatesExtractor(morph_vocab)\n",
    "\n",
    "def replace_date(x, token='DATE'):\n",
    "    date_extracts = list(dates_extractor(x))\n",
    "    if len(date_extracts) == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return_text = x\n",
    "        for date_extract in date_extracts: \n",
    "            st_idx = date_extract.start\n",
    "            end_idx = date_extract.stop            \n",
    "            return_text = return_text.replace(x[st_idx:end_idx], token)\n",
    "        return return_text\n",
    "\n",
    "def replace_address(x, token='ADDR'):\n",
    "    addr_extracts = list(addr_extractor(x))\n",
    "    if len(addr_extracts) == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return_text = x\n",
    "        for addr_extract in addr_extracts: \n",
    "            if addr_extract.fact.type in ['улица', 'дом']:\n",
    "                st_idx = addr_extract.start\n",
    "                end_idx = addr_extract.stop            \n",
    "                return_text = return_text.replace(x[st_idx:end_idx], token)\n",
    "        return return_text\n",
    "\n",
    "def replace_money(x, quantiles=None):\n",
    "    money_extracts = list(money_extractor(x))\n",
    "    if len(money_extracts) == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return_text = x\n",
    "        for money_extract in money_extracts:\n",
    "            st_idx = money_extract.start\n",
    "            end_idx = money_extract.stop\n",
    "            currency = money_extract.fact.currency\n",
    "            if currency != 'RUB':\n",
    "                return_text = return_text.replace(x[st_idx:end_idx], 'MONEY_F')\n",
    "                continue\n",
    "            amount = money_extract.fact.amount\n",
    "            if amount < 4631.79:\n",
    "                return_text = return_text.replace(x[st_idx:end_idx], 'MONEY_0')\n",
    "                continue\n",
    "            if amount <= 168830.91:\n",
    "                return_text = return_text.replace(x[st_idx:end_idx], 'MONEY_1')\n",
    "                continue\n",
    "            return_text = return_text.replace(x[st_idx:end_idx], 'MONEY_2')\n",
    "            \n",
    "        return return_text\n",
    "\n",
    "def money_in_span(x):\n",
    "    for money_token in ['MONEY_F', 'MONEY_0', 'MONEY_1', 'MONEY_2', 'DATE']:\n",
    "        if money_token in x:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def replace_org(x, leave_org = None):\n",
    "    doc = Doc(x)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "    return_text = x\n",
    "    for span in doc.spans:\n",
    "        if span.type == 'ORG':\n",
    "            if ((leave_org is not None) and (span.text in leave_org)) or money_in_span(span.text):\n",
    "                continue\n",
    "            else:\n",
    "                word = 'ORG'\n",
    "                return_text = return_text.replace(span.text, word)\n",
    "    return return_text\n",
    "\n",
    "org_freq = pd.read_csv('org_freq.csv')\n",
    "leave_org = (org_freq[org_freq.freq > 65].org_name.values).tolist()\n",
    "\n",
    "def prepare_russian_text(raw_text):\n",
    "    text = raw_text.lower()\n",
    "    text = text.replace('org', 'ORG').replace('money_', 'MONEY_')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_trans.csv')\n",
    "texts_train, targets_train = train_data.text, train_data.target\n",
    "val_data = pd.read_csv('val_trans.csv')\n",
    "texts_val, targets_val = val_data.text, val_data.target\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "\n",
    "def pipeline(text: str):\n",
    "    try:\n",
    "        text_dates_removed = replace_date(' '.join(text.split()), '')\n",
    "        # text_addr_replaced = replace_address(text_dates_removed)\n",
    "        # text_money_replaced = replace_money(text_addr_replaced)\n",
    "        text_money_replaced = replace_money(text_dates_removed)\n",
    "        text_money_org_replaced = replace_org(text_money_replaced, leave_org)\n",
    "        return prepare_russian_text(text_money_org_replaced)\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "\n",
    "pd.DataFrame({'text': texts_train.parallel_map(pipeline), 'target': targets_train}).to_csv('train_trans_DMO_2.csv')\n",
    "pd.DataFrame({'text': texts_val.parallel_map(pipeline), 'target': targets_val}).to_csv('val_trans_DMO_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "new_train_data = pd.read_csv('train_trans.csv')\n",
    "new_val_data = pd.read_csv('val_trans.csv')\n",
    "\n",
    "def pipeline(text: str):\n",
    "    try:\n",
    "        text = ' '.join(text.split())\n",
    "        text = text.replace('&quot;', '\"')\n",
    "        return text\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "# train_data = pd.read_csv('train_trans_DMO_2.csv')\n",
    "# texts_train, targets_train = train_data.text, train_data.target\n",
    "texts_train = pd.read_csv('interpreting-cnn-for-text/legal_dataset/train.txt.tok', header=None)\n",
    "targets_train = pd.read_csv('interpreting-cnn-for-text/legal_dataset/train.cat', header=None)\n",
    "\n",
    "# train_mask = list(new_train_data.text.map(pipeline).str.len() > 32)\n",
    "# pd.DataFrame({'text': texts_train.reset_index(drop=True)[train_mask], 'target': targets_train.reset_index(drop=True)[train_mask]}).to_csv('train_trans_DMO_3.csv', index=False)\n",
    "train_mask = list(new_train_data.text.map(pipeline).str.len() > 32)\n",
    "texts_train[train_mask].to_csv('interpreting-cnn-for-text/legal_dataset/train.txt.tok', index=False, header=False)\n",
    "targets_train[train_mask].to_csv('interpreting-cnn-for-text/legal_dataset/train.cat', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'рассматривается исковое заявление ОАО «Военно-страховая компания»\\xa0\\xa0 к ООО «Росгосстрах» о взыскании\\xa0 120000 руб. 00 коп.\\xa0 страхового возмещения.\\r\\nПредставители\\xa0 ОАО «Военно-страховая компания»\\xa0\\xa0 и ООО «Росгосстрах» в судебное заседание не'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.decoders import ByteLevel\n",
    "\n",
    "tokens = train_collater.tokenizer.tokenize(train_dataset[0][0].strip())\n",
    "for t in tokens:\n",
    "    print(ByteLevel().decode(t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/val functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# loss_fn = nn.BCEWithLogitsLoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_epoch(model, optimizer, sched, device):\n",
    "    loss_log, acc_log = [], []\n",
    "    model.train()\n",
    "    for data, target in tqdm(train_loader):\n",
    "        # data = data.to(device)\n",
    "        for key, value in data.items():\n",
    "            data[key] = value.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # output = model(data)\n",
    "        output = model(**data).logits\n",
    "\n",
    "        # loss = loss_fn(output, F.one_hot(target, num_classes=38).float())\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_log.append(loss.item())\n",
    "\n",
    "        preds = torch.argmax(output, dim=-1)\n",
    "        acc_log.append((preds == target).float().mean().item())\n",
    "\n",
    "        if sched is not None:\n",
    "            sched.step(loss_log[-1])\n",
    "    return loss_log, acc_log  \n",
    "\n",
    "def test(model, device):\n",
    "    loss_log, acc_log = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(val_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, F.one_hot(target, num_classes=38).float())\n",
    "            loss_log.append(loss.item())\n",
    "\n",
    "            preds = torch.argmax(output, dim=-1)\n",
    "            acc_log.append((preds == target).float().mean().item())\n",
    "    return loss_log, acc_log  \n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)    \n",
    "    points = np.array(val_history)\n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, sched, n_epochs, device, path_suffix=''):\n",
    "    train_loss_log, train_acc_log = [], []\n",
    "    val_loss_log, val_acc_log = [], []\n",
    "\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {0} of {1}\".format(epoch, n_epochs))\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, opt, sched, device)\n",
    "        val_loss, val_acc = test(model, device)\n",
    "        \n",
    "        train_loss_log.extend(train_loss)\n",
    "        train_acc_log.extend(train_acc)\n",
    "        \n",
    "        steps = len(train_dataset) / batch_size\n",
    "        val_loss_log.append((steps * (epoch + 1), np.mean(val_loss)))\n",
    "        val_acc_log.append((steps * (epoch + 1), np.mean(val_acc)))\n",
    "        \n",
    "        clear_output()\n",
    "        plot_history(train_loss_log, val_loss_log)\n",
    "        plot_history(train_acc_log, val_acc_log, title='accuracy')\n",
    "        \n",
    "        if val_acc_log[-1][1] > best_acc:\n",
    "            best_acc = np.mean(val_acc)\n",
    "            torch.save(model.state_dict(), f'./best_model{path_suffix}.pt')\n",
    "        \n",
    "        diff = val_acc_log[-1][1] - (val_acc_log[-2][1] if len(val_acc_log) > 1 else 0)\n",
    "        print(f'Last val accuracy = {val_acc_log[-1][1]:.4f} ({diff:+.4f})')\n",
    "        print(f'Best val accuracy = {best_acc:.4f}')\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'./best_model{path_suffix}.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 512\n",
    "N_FILTERS = 256\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 72\n",
    "DROPOUT_PROBA = 0.5\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT_PROBA).to(device)\n",
    "lr = 0.001\n",
    "n_epochs = 10\n",
    "opt = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "train(model, opt, None, n_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "gpu_id = 0\n",
    "device = torch.device(f'cuda:{gpu_id}') if gpu_id is not None else torch.device('cpu')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(backbone_model_name, num_labels=38)\n",
    "\n",
    "current_segment_embeddings = model.roberta.embeddings.token_type_embeddings.weight.data\n",
    "segment_embeddings = torch.cat(\n",
    "    [\n",
    "        current_segment_embeddings,\n",
    "        current_segment_embeddings + torch.rand_like(current_segment_embeddings) * 0.01\n",
    "    ]\n",
    ")\n",
    "model.roberta.embeddings.token_type_embeddings = model.roberta.embeddings.token_type_embeddings.from_pretrained(\n",
    "    segment_embeddings,\n",
    "    freeze=False\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "lr = 0.001\n",
    "n_epochs = 10\n",
    "opt = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "train(model, opt, None, n_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120574, 13398, 36)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(cat_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'text': train_dataset.texts, 'target': train_dataset.targets}).to_csv('train_trans.csv')\n",
    "pd.DataFrame({'text': val_dataset.texts, 'target': val_dataset.targets}).to_csv('val_trans.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
